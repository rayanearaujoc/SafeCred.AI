{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl_N8LgTj9TU"
      },
      "source": [
        "# **A – Ask the Data**\n",
        "## Como podemos identificar com precisão transações fraudulentas em um conjunto de dados altamente desbalanceado, minimizando falsos positivos e maximizando a detecção de fraudes, a fim de proteger clientes e instituições financeiras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgTfh68Fx_v0"
      },
      "source": [
        "# **G – Get the Data**\n",
        "\n",
        "No projeto, os dados vieram de um dataset público do Kaggle (https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data), específico para detecção de fraude em cartões de crédito. Esse conjunto disponibiliza 284.807 transações, das quais apenas 492 são fraudulentas (aprox. 0,17%).\n",
        "\n",
        "As variáveis de entrada são principalmente atributos anonimizados (V1, V2, ..., V28) resultantes de transformações PCA para proteger a privacidade, além de conter as colunas Time, Amount e a classe alvo (Class: fraudulenta ou legítima)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CC4Sd5iAjoyI",
        "outputId": "f5a6fee9-5a77-4f1d-c257-8f4f298a89ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "None\n",
            "                Time            V1            V2            V3            V4  \\\n",
            "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
            "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
            "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
            "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
            "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
            "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
            "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
            "\n",
            "                 V5            V6            V7            V8            V9  \\\n",
            "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
            "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
            "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
            "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
            "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
            "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
            "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
            "\n",
            "       ...           V21           V22           V23           V24  \\\n",
            "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
            "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
            "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
            "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
            "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
            "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
            "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
            "\n",
            "                V25           V26           V27           V28         Amount  \\\n",
            "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
            "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
            "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
            "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
            "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
            "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
            "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
            "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
            "\n",
            "               Class  \n",
            "count  284807.000000  \n",
            "mean        0.001727  \n",
            "std         0.041527  \n",
            "min         0.000000  \n",
            "25%         0.000000  \n",
            "50%         0.000000  \n",
            "75%         0.000000  \n",
            "max         1.000000  \n",
            "\n",
            "[8 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Load the dataset\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "# Inspect the data\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "197IviXWy9pz"
      },
      "source": [
        "# **E – Explore the Data**\n",
        "\n",
        "No projeto, começou-se verificando a qualidade dos dados: foi constatado que não havia valores nulos ou ausentes em nenhuma coluna. Além disso, notou-se que as colunas de atributos eram identificadas apenas como V1, V2, etc., devido à anonimização, o que limita a interpretação direta das features. Em termos de distribuição, identificou-se que a variável Amount (valor da transação) possuía uma escala muito diferente das demais features, exigindo normalização. O projeto aplicou um escalonamento (StandardScaler) nessa coluna de montante para trazê-la à mesma ordem de grandeza das outras variáveis. Também foi decidido remover a coluna Time, pois não agregava valor preditivo aparente ao modelo. Durante a exploração, reforçou-se a observação do desbalanceamento das classes – somente 0,17% das instâncias eram fraudes. Esse insight orientou etapas posteriores, pois ficou claro que técnicas especiais seriam necessárias para lidar com o desequilíbrio na modelagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I6ZDjmszyJJQ",
        "outputId": "01ac75fe-9984-40e7-bc1e-6179912a574d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OgBiRfhz-iBo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Scale the 'Amount' feature\n",
        "scaler = StandardScaler()\n",
        "df['Amount'] = scaler.fit_transform(df[['Amount']])\n",
        "# Drop 'Time' feature if it's not useful in your model\n",
        "df = df.drop(columns=['Time'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prPX7Uc2_td-"
      },
      "source": [
        "# **M – Model the Data**\n",
        "\n",
        "Primeiramente, o projeto realizou a separação dos dados em treino e teste (usando 80% para treino e 20% para teste), garantindo que essa divisão fosse estratificada. Em seguida, foram aplicadas técnicas para lidar com o desequilíbrio de classes antes e durante a modelagem, já que treinar um modelo na forma bruta dos dados poderia resultar em um classificador tendencioso para a classe majoritária. O artigo menciona abordagens de oversampling, como o SMOTE (Synthetic Minority Over-sampling Technique), que gera novas amostras sintéticas da classe fraudulenta para reforçar sua representatividade no treino. Também são discutidas estratégias de undersampling (reduzir amostras da classe majoritária) e o uso de ajuste de peso de classe nos algoritmos (por exemplo, definir `class_weight='balanced'` em modelos como Regressão Logística ou Random Forest) para dar maior peso às fraudes durante o aprendizado. Adicionalmente, considerando que fraudes são casos raros e “anomalias”, o projeto mencionou técnicas de detecção de anomalias como autoencoders, os quais podem ser treinados apenas nos dados não fraudulentos e identificar transações fora do padrão esperado como potenciais fraudes.\n",
        "\n",
        " Foram experimentados modelos clássicos como Regressão Logística e Árvore de Decisão, métodos baseados em instâncias como K-Vizinhos Mais Próximos (KNN), modelos de ensemble incluindo Random Forest e o algoritmo de boosting XGBoost, além de um Autoencoder configurado para detectar anomalias. Cada modelo foi avaliado com métricas apropriadas para problemas de classificação desbalanceada, especialmente Precision (precisão), Recall (sensibilidade), F1-Score e ROC-AUC, além da acurácia tradicional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DrRnU2PM_wXy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define X and y\n",
        "X = df.drop(columns=['Class'])  # Features\n",
        "y = df['Class']  # Target variable\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCWvMxwmDg5a",
        "outputId": "21ae4346-360c-445f-de7b-0d7969e03499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Performance:\n",
            "Accuracy: 0.974562\n",
            "Precision: 0.058785\n",
            "Recall: 0.918367\n",
            "F1 Score: 0.110497\n",
            "ROC AUC: 0.971447\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Treinar o modelo\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prever no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]  # probabilidades para ROC-AUC\n",
        "\n",
        "# Avaliar o desempenho\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.6f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.6f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.6f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.6f}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGKDGLpqFeAR",
        "outputId": "512d45a7-04f9-4788-d48d-2ed5842b4289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                Modelo  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
            "0  Logistic Regression  0.974562   0.058785  0.918367  0.110497  0.971447\n",
            "1        Decision Tree  0.999122   0.755319  0.724490  0.739583  0.862043\n",
            "2        Random Forest  0.999526   0.949367  0.765306  0.847458  0.958164\n",
            "3              XGBoost  0.999544   0.882979  0.846939  0.864583  0.969123\n",
            "4  K-Nearest Neighbors  0.999508   0.897727  0.806122  0.849462  0.943758\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# Calcular o peso para XGBoost\n",
        "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "# Dicionário com os modelos\n",
        "modelos = {\n",
        "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced'),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced'),\n",
        "    \"XGBoost\": XGBClassifier(scale_pos_weight=ratio, use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "}\n",
        "\n",
        "# Avaliação\n",
        "resultados = []\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    try:\n",
        "        y_proba = modelo.predict_proba(X_test)[:, 1]\n",
        "        roc_auc = roc_auc_score(y_test, y_proba)\n",
        "    except:\n",
        "        roc_auc = None\n",
        "\n",
        "    resultados.append({\n",
        "        \"Modelo\": nome,\n",
        "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 6),\n",
        "        \"Precision\": round(precision_score(y_test, y_pred), 6),\n",
        "        \"Recall\": round(recall_score(y_test, y_pred), 6),\n",
        "        \"F1 Score\": round(f1_score(y_test, y_pred), 6),\n",
        "        \"ROC AUC\": round(roc_auc, 6) if roc_auc is not None else None\n",
        "    })\n",
        "\n",
        "# Mostrar resultados em tabela\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7QPOeB2GsE6"
      },
      "source": [
        "# **C – Communicate the Data**\n",
        "\n",
        "Communicate the Data envolve interpretar os resultados obtidos e comunicá-los de forma clara. O projeto exemplificou bem essa etapa ao analisar os desempenhos de cada modelo e traduzir as métricas em implicações de negócio. No artigo, após apresentar os números de precisão, recall, etc., foram feitas explicações em texto comum destacando os trade-offs.\n",
        "\n",
        "Outra forma de comunicação de insights foi a explicação das métricas de desempenho em termos leigos e seu contexto. O texto dedicou uma seção para definir Acurácia, Precisão, Recall, F1 e ROC-AUC, junto com interpretações relevantes ao caso de uso. Por exemplo, enfatizou-se que, em detecção de fraude, uma alta precisão é importante para não rotular indevidamente muitas transações legítimas como fraudulentas (evitar falsos positivos), enquanto uma alta sensibilidade (recall) é crucial para não deixar fraudes reais passarem despercebidas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
